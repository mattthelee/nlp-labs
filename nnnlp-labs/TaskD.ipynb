{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data has been preprocessed by removing all the \" characters: sed -i 's/\"//g' *.txt\n",
    "# as this caused issues reading the data as a csv file. \n",
    "\n",
    "\n",
    "# Load the data\n",
    "fileGlob = glob.glob('./task1Data/twitter*.txt')\n",
    "traindf = pd.concat([pd.read_csv(f, sep='\\t', header=None, keep_default_na=False) for f in fileGlob], ignore_index = True)\n",
    "traindf.columns = ['id','label','text','date']\n",
    "'''\n",
    "string = traindf.loc[traindf['id'] == 425015646079184896].text\n",
    "pd.options.display.max_colwidth = 10000    \n",
    "display(string)'''\n",
    "traindf = traindf.drop(['id','date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "2nd day of #VINOOMANKAD U19:(ODI): Haryana\\u002c Kerala\\u002c Andhra\\u002c TN\\u002c Mumbai\\u002c Baroda\\u002c UP won their matches against J&K\\u002c KAR\\u002c Hyd\\u002cGoa\\u002c MH\\u002cBaroda\\u002cUP\n"
     ]
    }
   ],
   "source": [
    "# Sanity check to ensure tweets are tweet length\n",
    "maxi = 0\n",
    "for text in traindf.text:\n",
    "    length = len(text)\n",
    "    if length > maxi:\n",
    "        maxi = length\n",
    "        sanityCheck = text\n",
    "print(maxi)\n",
    "print(sanityCheck)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Things to try:\n",
    "Convert the text into vector my using a pre-trained system. \n",
    "Convert text into a vector by using a NN to train the embeddings. \n",
    "\n",
    "Looks like i need to handle the weird character replacement that's happening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to do some preprocessing on the data to remove stop words, punctuation and probably stem the words too. \n",
    "# Need to handle the /u002c and other unicdoe character artifacts that are happening. \n",
    "# If removing punctuation then may want to simply remove them \n",
    "# but if expanding contractinons will need to convert them first. - a library exists to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create index-word relationship\n",
    "word2idx = {'<PAD>': 0, '<UNK>' : 1, }\n",
    "idx2word ={}\n",
    "sents_as_ids = []\n",
    "for line in traindf.text:\n",
    "    sentId = []\n",
    "    for word in line.split():\n",
    "        if word in word2idx:\n",
    "            sentId.append(word2idx[word])\n",
    "            continue\n",
    "        count = len(word2idx)\n",
    "        word2idx[word] = count\n",
    "        idx2word[count] = word\n",
    "        sentId.append(count)\n",
    "    sents_as_ids.append(sentId)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 10000\n",
    "INDEX_FROM = 2\n",
    "\n",
    "MAXIMUM_LENGTH = 500\n",
    "print('Length of sample train_data before preprocessing:', len(train_data[0]))\n",
    "\n",
    "preprocessed_train_data = pad_sequences(train_data, MAXIMUM_LENGTH)\n",
    "print('Length of sample train_data after preprocessing:', len(preprocessed_train_data[0]))\n",
    "unpreprocessed_train_data = train_data\n",
    "train_data = preprocessed_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eenlp",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
