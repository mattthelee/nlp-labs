{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leem/anaconda3/envs/eenlp/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/leem/anaconda3/envs/eenlp/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import math\n",
    "import contractions\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.utils import plot_model, vis_utils\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import emoji\n",
    "import string\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data has been preprocessed by removing all the \" characters: sed -i 's/\"//g' *.txt\n",
    "# as this caused issues reading the data as a csv file. \n",
    "\n",
    "# Load the data\n",
    "fileGlob = glob.glob('./task2Data/*A.arabic.txt')\n",
    "\n",
    "traindf = pd.concat([pd.read_csv(f, sep='\\t', header=None, keep_default_na=False) for f in fileGlob], ignore_index = True)\n",
    "traindf.columns = ['id','label','raw']\n",
    "#traindf = traindf.drop(['date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tweet, stop_words):\n",
    "    # Convert emojis to words\n",
    "    tweet = emoji.demojize(tweet)\n",
    "    # Handle utf8 unicode problems\n",
    "    tweet = tweet.encode('utf8').decode('unicode_escape', 'ignore') \n",
    "    #tweet = contractions.fix(tweet)\n",
    "    tweetLine = word_tokenize(tweet)\n",
    "    # remove all tokens that are not alphabetic or stopwords, also lower the words\n",
    "    tweetLine = [word.lower() for word in tweetLine if word not in stop_words and word not in string.punctuation]\n",
    "    return tweetLine\n",
    "\n",
    "stop_words = stopwords.words('arabic')\n",
    "\n",
    "traindf['text'] = traindf.apply(lambda row: preprocess(row['raw'], stop_words),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2678\n",
      "['shihanh010', 'Ã¸Â¨Ã¹\\x88Ã¸Â´', 'Ã¹\\x88Ã¸Â§Ã¹\\x84Ã¸Â§', 'Ã¸Â§Ã¹\\x88Ã¸Â¨Ã¸Â§Ã¹', 'Ã¸Â§', 'face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy', ':face_with_tears_of_joy']\n",
      "140\n",
      "['Ã¯Âº\\x87Ã¯Âº', 'Â«', 'Ã¯Âº\\x8d', 'Ã¯', 'Â»', 'Â§Ã¯', 'Â»', '\\x84Ã¯', 'Â»', '\\x96', 'Ã¯Âº\\x8dÃ¯', 'Â»', '\\x9fÃ¯ÂºÂ°Ã¯', 'Â»', '\\x8bÃ¯', 'Â»', 'Â´Ã¯', 'Â»', 'Â¢', 'Ã¯', 'Â»', '\\x93Ã¯', 'Â»', 'Â¼', 'Ã¯Âº\\x97Ã¯Âº', 'Ã¯Âº\\x92Ã¯', 'Â»', 'ÂªÃ¹\\x8f', 'Ã¯', 'Â»', '\\x93Ã¯ÂºÂ¨Ã¯', 'Â»', 'Â´Ã¯ÂºÂ®Ã¹\\x8c', 'Ã¯', 'Â»', 'Â£Ã¯', 'Â»', 'Â¦', 'Ã¯Âº\\x87Ã¯Âº\\x9fÃ¯Âº\\x8eÃ¯Âº\\x91Ã¯Âº\\x98Ã¯', 'Â»', 'Âª', 'Ã¯Âº\\x8dÃ¯', 'Â»', '\\x9fÃ¯', 'Â»', '\\x8cÃ¯ÂºÂ´Ã¯', 'Â»', 'Â´Ã¯ÂºÂ®Ã¯', 'Â»', 'Â±Ã¯', 'Â»', '\\xadÃ¯', 'Â»', 'Â»', 'Ã¯Âº\\x97Ã¯ÂºÂ®Ã¯', 'Â»', '\\x9bÃ¯', 'Â»', 'Â¦', 'Ã¯', 'Â»', '\\x8bÃ¯', 'Â»', 'Ã¯', 'Â»', 'Â°', 'Ã¯Âº\\x87Ã¯', 'Â»', 'Â³Ã¯ÂºÂ®Ã¯Âº\\x8dÃ¯', 'Â»', 'Â¥', 'Ã¯', 'Â»', 'Â³Ã¯', 'Â»', 'Â®Ã¯', 'Â»', 'Â£Ã¯Âº\\x8eÃ¹\\x8b', 'Ã¯', 'Â»', '\\xadÃ¯', 'Â»', 'Â»', 'Ã¯Âº\\x97Ã¯', 'Â»', 'Â®Ã¯', 'Â»', 'Â§Ã¯', 'Â»', 'Â²', 'Ã¯Âº\\x91Ã¯', 'Â»', 'Ã¯', 'Â»', 'Â´Ã¯ÂºÂ®', 'Ã¯Âº\\x83Ã¯', 'Â»', '\\xad', 'Ã¯Âº\\x9fÃ¯', 'Â»', 'Â®Ã¯', 'Â»', 'Â¥', 'Ã¯', 'Â»', '\\x9bÃ¯', 'Â»', 'Â´Ã¯ÂºÂ®Ã¯', 'Â»', 'Â±Ã¯Âº\\x83Ã¯Âº\\xadÃ¯', 'Â»', 'Â¯', 'Ã¯Âº\\x8dÃ¯', 'Â»', '\\x9fÃ¯', 'Â»', 'Â¤Ã¯ÂºÂ¨Ã¯', 'Â»', 'Ã¯', 'Â»', 'Â®Ã¯', 'Â»', '\\x89', 'Ã¯', 'Â»', '\\x93Ã¯', 'Â»', 'Â²', 'Ã¯Âº\\x8dÃ¯', 'Â»', '\\x9fÃ¯Âº\\x98Ã¯', 'Â»', 'Ã¯', 'Â»', '\\x94Ã¯Âº\\x8eÃ¯ÂºÂ¯', 'Ã¯', 'Â»', 'Â³Ã¯', 'Â»', 'Â¬Ã¯ÂºÂ¬']\n"
     ]
    }
   ],
   "source": [
    "# Sanity check to ensure tweets are tweet length\n",
    "maxi = 0\n",
    "for text in traindf.text:\n",
    "    length = len(' '.join(text))\n",
    "    if length > maxi:\n",
    "        maxi = length\n",
    "        sanityCheck = text\n",
    "print(maxi)\n",
    "print(sanityCheck)\n",
    "\n",
    "maxi = 0\n",
    "for text in traindf.text:\n",
    "    length = len(text)\n",
    "    if length > maxi:\n",
    "        maxi = length\n",
    "        sanityCheck = text\n",
    "print(maxi)\n",
    "print(sanityCheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1021    @shihanh010 Ø¨ÙˆØ´ ÙˆØ§Ù„Ø§ Ø§ÙˆØ¨Ø§Ù…Ø§ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚\n",
      "Name: raw, dtype: object\n",
      "1021    [shihanh010, Ã¸Â¨Ã¹ÂˆÃ¸Â´, Ã¹ÂˆÃ¸Â§Ã¹Â„Ã¸Â§, Ã¸Â§Ã¹ÂˆÃ¸Â¨Ã¸Â§Ã¹, Ã¸Â§, face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, :face_with_tears_of_joy, ...]\n",
      "Name: text, dtype: object\n",
      "1021    neutral\n",
      "Name: label, dtype: object\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 10000\n",
    "sample = traindf.loc[traindf.id == 785620354970574848]\n",
    "\n",
    "print(sample.raw)\n",
    "print(sample.text)\n",
    "print(sample.label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1021', '@', 'shihanh010', 'Ã˜Â¨Ã™\\x88Ã˜Â´', 'Ã™\\x88Ã˜Â§Ã™\\x84Ã˜Â§', 'Ã˜Â§Ã™\\x88Ã˜Â¨Ã˜Â§Ã™', 'Ã˜Â§', ':', 'face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':', ':face_with_tears_of_joy', ':']\n"
     ]
    }
   ],
   "source": [
    "tweet = sample.raw.to_string()\n",
    "tweet = emoji.demojize(tweet)\n",
    "tweet = tweet.encode('utf8').decode('unicode_escape', 'ignore') \n",
    "tweetLine = word_tokenize(tweet)\n",
    "print(tweetLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create index-word relationship\n",
    "word2idx = {'<PAD>': 0, '<UNK>' : 1, }\n",
    "idx2word ={}\n",
    "sents_as_ids = []\n",
    "for line in traindf.text:\n",
    "    sentId = []\n",
    "    for word in line:\n",
    "        if word in word2idx:\n",
    "            sentId.append(word2idx[word])\n",
    "            continue\n",
    "        count = len(word2idx)\n",
    "        word2idx[word] = count\n",
    "        idx2word[count] = word\n",
    "        sentId.append(count)\n",
    "    sents_as_ids.append(sentId)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertTextToNumSeq(text, word2idx,MAXIMUM_LENGTH):\n",
    "    numSeq = []\n",
    "    for word in text:\n",
    "        if word in word2idx:\n",
    "            numSeq.append(word2idx[word])\n",
    "        else:\n",
    "            # If unseen put in unknown\n",
    "            numSeq.append(1) \n",
    "                \n",
    "    numSeq = pad_sequences([numSeq],MAXIMUM_LENGTH )\n",
    "    return numSeq\n",
    "\n",
    "MAXIMUM_LENGTH = 150 # Motivated because max sequence of words i had was 140, char limit is 140 so this should be max\n",
    "\n",
    "traindf['numSeq'] = traindf.apply(lambda row: convertTextToNumSeq(row['text'], word2idx, MAXIMUM_LENGTH),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral     368\n",
      "negative    285\n",
      "positive    186\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split val and training data\n",
    "x_train, x_val, y_train, y_val = train_test_split(traindf.numSeq, traindf.label, stratify=traindf.label, random_state =2)\n",
    "print(y_val.value_counts())\n",
    "x_train = np.array([x for y in x_train for x in y]).reshape(len(x_train),MAXIMUM_LENGTH)\n",
    "x_val = np.array([x for y in x_val for x in y]).reshape(len(x_val),MAXIMUM_LENGTH)\n",
    "\n",
    "#Y data is categorical therefore must be converted to a vector\n",
    "onehot_encoder = OneHotEncoder(sparse=False,categories='auto')\n",
    "y_train = onehot_encoder.fit_transform(np.array(y_train).reshape(len(y_train),1))\n",
    "y_val = onehot_encoder.transform(np.array(y_val).reshape(len(y_val),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 150, 100)          3000000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 3,080,703\n",
      "Trainable params: 3,080,703\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create LSTM model \n",
    "VOCAB_SIZE = 30000\n",
    "\n",
    "EMBED_SIZE = 100\n",
    "model = Sequential()\n",
    "model.add(Embedding(VOCAB_SIZE, EMBED_SIZE,input_length=MAXIMUM_LENGTH))\n",
    "model.add(LSTM(100))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2516 samples, validate on 839 samples\n",
      "Epoch 1/5\n",
      "2516/2516 [==============================] - 5s 2ms/step - loss: 1.0757 - acc: 0.4304 - val_loss: 1.0517 - val_acc: 0.4374\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.43743, saving model to task2Weights.best.hdf5\n",
      "Epoch 2/5\n",
      "2516/2516 [==============================] - 4s 2ms/step - loss: 0.9865 - acc: 0.5223 - val_loss: 1.0179 - val_acc: 0.4744\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.43743 to 0.47437, saving model to task2Weights.best.hdf5\n",
      "Epoch 3/5\n",
      "2516/2516 [==============================] - 4s 2ms/step - loss: 0.6696 - acc: 0.7190 - val_loss: 1.0225 - val_acc: 0.5268\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.47437 to 0.52682, saving model to task2Weights.best.hdf5\n",
      "Epoch 4/5\n",
      "2516/2516 [==============================] - 4s 2ms/step - loss: 0.2409 - acc: 0.9455 - val_loss: 1.1971 - val_acc: 0.5471\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.52682 to 0.54708, saving model to task2Weights.best.hdf5\n",
      "Epoch 5/5\n",
      "2516/2516 [==============================] - 4s 2ms/step - loss: 0.0765 - acc: 0.9849 - val_loss: 1.3249 - val_acc: 0.5316\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.54708\n"
     ]
    }
   ],
   "source": [
    "# Save the best weights to a file so we get the model with the best val acc\n",
    "weightsFilePath=\"task2Weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(weightsFilePath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "history = model.fit(x_train,y_train,epochs=5,batch_size=128,validation_data=(x_val, y_val),callbacks=[checkpoint],verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl4FeXZ+PHvTUhIQhIgJGELEGQPiyxhEai7VasF6wqKLILa9mfV2k37Wqt2eX1t31ZbW/talrAoaNUqtVJrW20VlBB2CKAICQkECGsSIPv9+2MmySEk5LCczMnJ/bmuc2WW58y5z8CZe+Z5Zp5HVBVjjDEGoJXXARhjjAkelhSMMcbUsKRgjDGmhiUFY4wxNSwpGGOMqWFJwRhjTA1LCibkiEiKiKiItPaj7AwR+bgp4mpqIvIlEdnudRymebGkYDwlItkiUiYiCXWWr3MP7CneRHZKLDEiUiwiy72O5Wyo6keq2t/rOEzzYknBBINdwJTqGREZAkR7F85pbgFKgWtEpHNTfrA/VzvGXEiWFEwwWARM85mfDiz0LSAi7URkoYgUiEiOiDwuIq3cdWEi8ksROSgiO4Eb6nnvXBHJF5E9IvJTEQk7i/imA38ANgJT62y7u4i86cZ1SERe8Fl3r4hsFZEiEckSkRHuchWRPj7l0kXkp+705SKSJyI/EJF9wHwR6SAi77ifccSdTvZ5f7yIzBeRve76t3y35VOuq4i84W5nl4g86LNutIhkikihiOwXkV+dxf4xIcSSggkGnwJxIjLQPVhPBhbXKfNboB1wEXAZThKZ6a67F7gRGA6kAbfWeW86UAH0cct8GZjtT2Ai0hO4HHjZfU3zWRcGvAPkAClAN2Cpu+424Em3fBwwETjkz2cCnYF4oCdwH87vdL473wM4CbzgU34RzpXVICAJ+HU936MV8BdggxvnVcDDInKtW+R54HlVjQN6A6/5GasJNapqL3t59gKygauBx4H/Bq4D3gdaA4pzsA0DyoBUn/fdD3zoTv8L+LrPui+7720NdMKp+onyWT8F+MCdngF8fIb4HgfWu9PdgEpguDt/CVAAtK7nfe8BDzWwTQX6+MynAz91py93v2vkGWIaBhxxp7sAVUCHespdDuS502OA3XXWPwbMd6f/AzwFJHj9f8Je3r6svtIEi0U4B6Ze1Kk6AhKAcJwz8mo5OAdpgK5Abp111Xq6780XkeplreqUP5NpwB8BVHWPiPwbpzppHdAdyFHVinre1x34ws/PqKtAVUuqZ0QkGufs/zqgg7s41r1S6Q4cVtUjjWyzJ9BVRI76LAsDPnKnZwFPA9tEZBfwlKq+c47xm2bMqo9MUFDVHJwG568Ab9ZZfRAoxzmwVesB7HGn83EOjr7rquXiXCkkqGp79xWnqoMai0lExgF9gcdEZJ9bxz8GuNNtAM4FejTQGJyLUw1TnxOc2pBet/G6btfF3wH6A2PUqd65tDpE93PiRaR9I18nF9jlsw/aq2qsqn4FQFU/V9UpONVP/wO8LiJtG9mmCUGWFEwwmQVcqarHfReqaiVOHffPRCTWred/hNp2h9eAB0UkWUQ6AI/6vDcf+DvwvyISJyKtRKS3iFzmRzzTcaqyUnGqbIYBg4Eo4HogAychPSMibUUkUkTGu++dA3xXREaKo48bN8B6nMQSJiLX4bSRnEksTjvCURGJB35c5/stB37vNkiHi8il9WwjAyhyG7Cj3M8eLCKjAERkqogkqmoVUH01UeXHPjIhxpKCCRqq+oWqZjaw+lvAcWAn8DHwCjDPXfdHnDr8DcBaTr/SmAZEAFnAEeB1nLr4BolIJHA78FtV3efz2oVT1TXdTVZfxWnA3g3kAXe43+VPwM/cOIuAt3AajwEect93FLjLXXcmz+EkooM4jfJ/q7P+bpwrqW3AAeDhuhtwY70RJ7Htcrc1B6fxHpyqqS0iUozT6DxZVU82EpcJQaJqg+wYY4xx2JWCMcaYGpYUjDHG1LCkYIwxpoYlBWOMMTWa3cNrCQkJmpKS4nUYxhjTrKxZs+agqiY2Vq7ZJYWUlBQyMxu6a9EYY0x9RCSn8VIBrD4SkXkickBENjewXkTkNyKyQ0Q2VvcgaYwxxjuBbFNIx3kgpiHX43Qh0BenJ8gXAxiLMcYYPwQsKajqf4DDZygyCViojk+B9iJyxqdMjTHGBJaXbQrdOLWnyjx3WX7dgiJyH87VBD169Ki7mvLycvLy8igpKTltXaiKjIwkOTmZ8PBwr0MxxoSQZtHQrKovAS8BpKWlndYvR15eHrGxsaSkpODTPXLIUlUOHTpEXl4evXr18jocY0wI8fI5hT2c2t1xMrVdIZ+VkpISOnbs2CISAoCI0LFjxxZ1ZWSMaRpeJoVlwDT3LqSxwDG3G+Bz0lISQrWW9n2NMU0jYNVHIrIEZzjABHfw8B/jjICFqv4BeBdnQJUdOIOOzKx/S8YY0zKpKnlHTrI1v5Ct+UVcNTCJwd3aNf7G8xCwpOCO4nSm9Qr8v0B9flM6dOgQV111FQD79u0jLCyMxETnwcGMjAwiIiIa3cbMmTN59NFH6d+/f0BjNcYEp5LySj7bX1STALLyC9maX0hRiTPaqwjEx0Q036TQknTs2JH169cD8OSTTxITE8N3v/vdU8pUD4rdqlX9NXbz588PeJzGGO+pKgVFpe5BvzoJFLLz4HEqq5z7aNpGhDGgSxyThnVlYJc4BnaJY0DnWKIjAn/ItqQQQDt27GDixIkMHz6cdevW8f777/PUU0+xdu1aTp48yR133METTzwBwIQJE3jhhRcYPHgwCQkJfP3rX2f58uVER0fz9ttvk5SU5PG3McacrfLKKr4oKK45+9+aX0jW3kIOHS+rKdOtfRQDu8Rx/eDONQmgR3w0rVp5024Ycknhqb9sIWtv4QXdZmrXOH781UbHea/Xtm3bWLhwIWlpaQA888wzxMfHU1FRwRVXXMGtt95KamrqKe85duwYl112Gc888wyPPPII8+bN49FHH61v88aYIHH0RNlpZ/+f7y+mrNIZ6jqidSv6d4rlqoFJNQf/gZ3jaBcdXM8ahVxSCDa9e/euSQgAS5YsYe7cuVRUVLB3716ysrJOSwpRUVFcf/31AIwcOZKPPvqoSWM2xjSsqkrJPnT8lIP/1vxC9h6rvUU8IaYNA7vEMnNCCqluArgooS2tw4J/tIKQSwrnekYfKG3btq2Z/vzzz3n++efJyMigffv2TJ06td5nDXwbpsPCwqioqGiSWI0xpzpeWsG2fYVk+SSA7fuKOFFWCUBYK6F3YltG94qvPfvvEkdibBuPIz93IZcUgllhYSGxsbHExcWRn5/Pe++9x3XXnanPQGNMU1BV9h4rIWtv4Sln/zmHT6BuHwpxka0Z2CWOO0Z1Z2CXOFK7xNEnKYbI8DBvg7/ALCk0oREjRpCamsqAAQPo2bMn48eP9zokY1qckvJKdhwoJmtvYc1tn1vzCyksqb0iT+kYzcAucdw8Itmp/ukaR9d2kS3ioVFRPa0roaCWlpamdQfZ2bp1KwMHDvQoIu+01O9tjL8KikqdO358Dv5fFNTe+hkdEUb/zrE11T6p7q2fbduE3vmyiKxR1bTGyoXeNzfGtDgVlVXsPHi85pbP6ruADhaX1pTp2i6SgV3i+HKqc+tnatc4enp462ewsqRgjGlWjp0srznrz9pbyNZ9hXy2v5iyCvfWz7BW9O0Uw+X9E90rgFhSu8TRPrrxngWMJQVjTJCqqlJ2Hz5RmwDcs/89R0/WlOnYNoLUrnHMGJfCwC5ONVDvxBjCm8Gtn8HKkoIxxnMnyirYtq/olCuA7fuKOO7e+tlKoHdiDCN7dmDq2J41Z/+JsW1aRONvU7KkYIxpcqUVlSz6JId1u4+SlV9I9qHjNbd+xrq3ft6W1r3m7L9fp9iQu/UzWFlSMMY0qYrKKh5eup7lm/fRIz6a1C5x3DSsW00CSO4QZWf/HrKkcAFcccUVPProo1x77bU1y5577jm2b9/Oiy++WO97YmJiKC4ubqoQjQkKVVXKo29uYvnmfTx+w0Bmf+kir0MydVhrzAUwZcoUli5desqypUuXMmXKGYeUMKZFUVWefieL19fk8dBVfS0hBClLChfArbfeyl//+lfKypzucLOzs9m7dy/Dhw/nqquuYsSIEQwZMoS3337b40iN8c6v3/+M9JXZzJrQi4ev7ut1OKYBoVd9tPxR2Lfpwm6z8xC4/pkGV8fHxzN69GiWL1/OpEmTWLp0KbfffjtRUVH8+c9/Ji4ujoMHDzJ27FgmTpxo9aWmxXnpP1/wm3/t4I607jx+w0D7DQQxu1K4QHyrkKqrjlSVH/7whwwdOpSrr76aPXv2sH//fo8jNaZpvbJqNz9/dxs3DO3Cz28eYgkhyIXelcIZzugDadKkSXz7299m7dq1nDhxgpEjR5Kenk5BQQFr1qwhPDyclJSUervKNiZUvb1+D//11iYu75/Ir28fRph1KRH07ErhAomJieGKK67gnnvuqWlgPnbsGElJSYSHh/PBBx+Qk5PjcZTGNJ1/bt3Pd17bwKiUeF68ayQRre1w0xzYv9IFNGXKFDZs2FCTFO666y4yMzMZMmQICxcuZMCAAR5HaEzTWPnFQb7x8lpSu8Yxd3oaURH24FlzEXrVRx666aab8O2KPCEhgU8++aTesvaMgglV63Yf4d4FmaR0jGbBzNHERgbXGMTmzOxKwRhzwWzNL2TG/NV0jGnD4llj6NDWeiZtbiwpGGMuiF0Hj3P33AyiwsN4efYYkuIivQ7JnIOQSQrNbQS589XSvq8JbnuPnmTqnFVUqbJ49mi6x0d7HZI5RwFNCiJynYhsF5EdIvJoPet7isg/RWSjiHwoIsnn8jmRkZEcOnSoxRwoVZVDhw4RGWlnYsZ7B4tLmTpnFYUny1l4z2j6JMV6HZI5DwFraBaRMOB3wDVAHrBaRJapapZPsV8CC1V1gYhcCfw3cPfZflZycjJ5eXkUFBRciNCbhcjISJKTzymHGnPBHDtRzt1zM9h77CSLZo1hcLd2XodkzlMg7z4aDexQ1Z0AIrIUmAT4JoVU4BF3+gPgrXP5oPDwcHr16nUeoRpjztbx0gpmpmew40ARc6aPYlRKvNchmQsgkNVH3YBcn/k8d5mvDcDN7vTXgFgR6RjAmIwxF0BJeSX3L1rD+tyj/GbycC7rl+h1SOYC8bqh+bvAZSKyDrgM2ANU1i0kIveJSKaIZLakKiJjglFFZRUPLlnHxzsO8uytF3P9kC5eh2QuoEAmhT1Ad5/5ZHdZDVXdq6o3q+pw4L/cZUfrbkhVX1LVNFVNS0y0MxJjvFJVpXz/9Y38PWs/T341lVtHWrtWqAlkUlgN9BWRXiISAUwGlvkWEJEEEamO4TFgXgDjMcacB1Xlx8u28Oa6PXznmn7MGG/teKEoYElBVSuAB4D3gK3Aa6q6RUSeFpGJbrHLge0i8hnQCfhZoOIxxpyfX7y3nUWf5nDfpRfxwJV9vA7HBEhA+z5S1XeBd+sse8Jn+nXg9UDGYIw5f7//cAe///ALpozuwWPXD7AxEUKY1w3Nxpggt+iTbJ7923YmDevKT28abAkhxFlSMMY06M/r8vjR21u4emASv7ztYhskpwWwpGCMqdd7W/bx3T9t5JKLOvLCnSMID7PDRUtg/8rGmNN8/PlBvvXKOoZ0a8cfp6cRGW6D5LQUlhSMMadYk3OYexdmclFiW9JnjiKmjY3F1ZJYUjDG1Niy9xgz5q+mU1wbFs4aTftoGySnpbGkYIwB4IuCYqbNzSC2TWsWzx5DUqx1zd4SWVIwxpB35ART56wCYNHsMSR3sEFyWiqrLDSmhTtQVMLUOasoLq1g6X1j6Z0Y43VIxkN2pWBMC3b0RBnT5mawv7CU9JmjGNTVBslp6SwpGNNCFZdWMH3+anYWHOeP09IY2dMGyTFWfWRMi1RSXsm9CzLZvOcYL941ggl9E7wOyQQJu1IwpoUpr6zigVfW8snOQ/zytqF8eVBnr0MyQcSSgjEtSGWV8p3XNvCPrQf4yaRBfG24DZJjTmVJwZgWQlV5/K3NLNuwl+9f15+7L0nxOiQThCwpGNMCqCr/vXwbSzJ2843Le/PNy22QHFM/SwrGtAAv/GsHL/1nJ3eP7cn3r+3vdTgmiFlSMCbEzV+xi/99/zNuHt6NpyYOskFyzBlZUjAmhP0pM5en/pLFl1M78eytQ2llg+SYRlhSMCZELd+Uzw/e2MiEPgn89s7htLZBcowf7H+JMSHo358V8ODSdQzr3p6Xpo2kTWsbJMf4x5KCMSFmdfZh7l+USd+kWObPHE10hHVcYPxnScGYELJ5zzHumb+aru2jWDhrNO2iwr0OyTQzlhSMCRE7DhQxbV4GcVHhLJ41hoSYNl6HZJohSwrGhIDcwye4a84qWomwePYYuraP8jok00xZUjCmmdtfWMJdc1ZRUl7F4tmj6ZXQ1uuQTDNmScGYZuzw8TKmzlnFwWJnkJwBneO8Dsk0cwFNCiJynYhsF5EdIvJoPet7iMgHIrJORDaKyFcCGY8xoaSopJzp8zLIOXyCOdPTGN6jg9chmRAQsKQgImHA74DrgVRgioik1in2OPCaqg4HJgO/D1Q8xoSSk2WVzFqQydb8Ql68awTjetsgOebCCOSVwmhgh6ruVNUyYCkwqU4ZBaqvd9sBewMYjzEhoayiim+8vIbV2Yf51R3DuGpgJ69DMiEkkEmhG5DrM5/nLvP1JDBVRPKAd4Fv1bchEblPRDJFJLOgoCAQsRrTLFRWKd9+dT0fbi/gZzcNYeLFXb0OyYQYrxuapwDpqpoMfAVYJCKnxaSqL6lqmqqmJSYmNnmQxgQDVeWHb27ir5vy+eFXBnDnmB5eh2RCUCCTwh6gu898srvM1yzgNQBV/QSIBKxy1Jg6VJWfvLOVVzNz+daVfbjv0t5eh2RCVCCTwmqgr4j0EpEInIbkZXXK7AauAhCRgThJweqHjKnjuX98zrwVu5gxLoVHrunndTgmhAUsKahqBfAA8B6wFecuoy0i8rSITHSLfQe4V0Q2AEuAGaqqgYrJmOZozkc7ef6fn3PryGSeuDHVBskxARXQ7hNV9V2cBmTfZU/4TGcB4wMZgzHN2aurd/PTv27l+sGdeebmITZIjgk4rxuajTENeGfjXh59cxOX9kvkucnDbJAc0yTsf5kxQeiDbQd4eOl60np24P+m2iA5pulYUjAmyHy68xBfX7yGAV1imTtjFFERlhBM07GkYEwQ2ZB7lFnpq+keH83Ce8YQF2mD5JimZUnBmCCxfV8R0+dnEB8TweJZY4hvG+F1SKYFsqRgTBDIOXScqXNXERHWipdnjaVzu0ivQzItlCUFYzyWf+wkd81ZRUVlFYtnj6FHx2ivQzItWKNJQUS+JSLWUbsxAXCouJSpc1Zx9EQ5C+4ZTb9OsV6HZFo4f64UOgGrReQ1d9Ace3rGmAvg2Mlyps3LIO/ISeZOT2NocnuvQzKm8aSgqo8DfYG5wAzgcxH5uYhYj1zGnKMTZRXMSl/NZ/uL+MPdIxlzUUevQzIG8LNNwe2PaJ/7qgA6AK+LyLMBjM2YkFRaUcn9i9awdvcRnrtjOFf0T/I6JGNqNNr3kYg8BEwDDgJzgO+park77sHnwPcDG6IxoaOisoqHlqzno88P8uwtQ7lhaBevQzLmFP50iBcP3KyqOb4LVbVKRG4MTFjGhJ6qKuUHb2zib1v28aMbU7l9VPfG32RME/On+mg5cLh6RkTiRGQMgKpuDVRgxoQSVeXpd7J4Y20eD1/dl1kTenkdkjH18icpvAgU+8wXu8uMMX76379/RvrKbGZP6MVDV/X1OhxjGuRPUhDfgW9UtYoAj8NgTCj5v39/wQsf7GDyqO781w0DbZAcE9T8SQo7ReRBEQl3Xw8BOwMdmDGh4OVVOfz38m3cOLQLP/vaEEsIJuj5kxS+DowD9gB5wBjgvkAGZUwoeHv9Hh5/azNX9E/kV7cPI8xGTTPNQKPVQKp6AJjcBLEYEzL+kbWfR17bwOiUeF6cOpKI1tbNmGke/HlOIRKYBQwCarpuVNV7AhiXMc3Wyh0H+eYraxncNY4509OIDLdBckzz4c/pyyKgM3At8G8gGSgKZFDGNFdrdx9h9sJMUjpGkz5zNLE2SI5pZvxJCn1U9UfAcVVdANyA065gjPGxNb+QGfMySIxtw+JZY+hgg+SYZsifpFDu/j0qIoOBdoB11mKMj8/3F3H33AyiI1qzeNYYkuJskBzTPPnzvMFL7ngKjwPLgBjgRwGNyphmZN3uI8xMX014WCsWzx5N93gbJMc0X2dMCm6nd4WqegT4D3BRk0RlTDPx0ecF3L9oDQkxbVg0azQ9O7b1OiRjzssZq4/cp5etF1Rj6vHXjfnck76aHvHRvP71SywhmJDgT5vCP0TkuyLSXUTiq18Bj8yYIPbyqhweWLKWi5Pb8+p9l1gbggkZ/rQp3OH+/X8+yxQ/qpJE5DrgeSAMmKOqz9RZ/2vgCnc2GkhSVRuT0AQtVeX3H37BL97bzhX9E/n9XSOJirDnEEzo8OeJ5nPq41dEwoDfAdfgdI+xWkSWqWqWz7a/7VP+W8Dwc/ksY5pCVZXys3e3MvfjXdw0rCu/uO1iwsPsSWUTWvx5onlafctVdWEjbx0N7FDVne52lgKTgKwGyk8BftxYPMZ4obyyih+8sZE31+5hxrgUnrgxlVbWl5EJQf5UH43ymY4ErgLWAo0lhW5Ars98dWd6pxGRnkAv4F8NrL8PtxO+Hj16+BGyMRdOSXklD7yyln9sPcAj1/TjW1f2sd5OTcjyp/roW77zItIeWHqB45gMvK6qlQ3E8BLwEkBaWprWV8aYQCgsKWd2eiarcw7zk5sGc/fYnl6HZExAnctgOcdxzuobswfwHYQ22V1Wn8mc2pBtjOcKikqZNi+Dz/cX8fzk4Uy8uKvXIRkTcP60KfwF524jcG5hTQVe82Pbq4G+ItILJxlMBu6sZ/sDgA7AJ37GbEzA5R4+wd1zV7G/sJQ509O4vL/17GJaBn+uFH7pM10B5KhqXmNvUtUKEXkAeA/nltR5qrpFRJ4GMlV1mVt0MrDUd8hPY7y0fV8Rd89dRWlFFYtnj2Fkzw5eh2RMk/EnKewG8lW1BEBEokQkRVWzG3ujqr4LvFtn2RN15p/0O1pjAmxNzhFmzs8gMjyM1+6/hP6dY70OyZgm5c9N1n8CqnzmK91lxoSUD7cfYOqcVcS3jeCNb4yzhGBaJH+uFFqraln1jKqWiYh1FG9Cytvr9/Cd1zbQr1MsC+4ZTWJsG69DMsYT/lwpFIjIxOoZEZkEHAxcSMY0rUWfZPPwq+sZ0bMDS+8fawnBtGj+XCl8HXhZRF5w5/OAep9yNqY5UVV+888d/Pofn3H1wE68cOdwG0/ZtHj+PLz2BTBWRGLc+eKAR2VMgFVVKU+/k0X6ymxuGZHM/9wyhNbWj5ExjVcficjPRaS9qhararGIdBCRnzZFcMYEQnllFd9+bT3pK7OZPaEXv7h1qCUEY1z+/BKuV9Wj1TPuKGxfCVxIxgTOybJK7l2Yydvr9/K9a/vzXzcMtI7tjPHhT5tCmIi0UdVScJ5TAKwlzjQ7x06UM2vBatbsPsLPvzaEO8dY54rG1OVPUngZ+KeIzAcEmAEsCGRQxlxoBwpLmDYvg50Fx/ndnSP4ypAuXodkTFDyp6H5f0RkA3A1Th9I7wHWVaRpNnIOHWfq3FUcKi5j3oxRTOib4HVIxgQtf3tJ3Y+TEG4DdgFvBCwiYy6grL2FTJuXQWVVFa/cO5Zh3W20V2POpMGkICL9cEZDm4LzsNqrgKjqFQ29x5hgsjr7MPekryamTWuW3ncJfZKs2wpjGnOmK4VtwEfAjaq6A0BEvn2G8sYEjX9t2883Fq+lW4coFs0aQ7f2UV6HZEyzcKZbUm8G8oEPROSPInIVTkOzMUHtz+vyuHfhGvp1iuVP919iCcGYs9BgUlDVt1R1MjAA+AB4GEgSkRdF5MtNFaAxZ2P+il18+9UNjE6JZ8l9Y+kYY3dPG3M2Gn14TVWPq+orqvpVnCE11wE/CHhkxpwFVeVXf9/OU3/J4tpBnZg/cxQxbc5ltFljWraz+tW4TzO/5L6MCQqVVcqPl21m8ae7uSOtOz/72mDrtsKYc2SnUqZZK6uo4pHX1vPOxnzuv+wiHr1uACLW9GXMubKkYJqtE2UV3L9oDR99fpDHrh/A/Zf19jokY5o9SwqmWTp6ooyZ6avZkHuUZ28Zyu2junsdkjEhwZKCaXb2HSth2rxVZB86wYtTR3LtoM5eh2RMyLCkYJqVXQePM3XOKo6dLCd95ijG9bZ+jIy5kCwpmGZj855jTJ+XgQJL7h3LkOR2XodkTMixpGCahU93HuLeBZnERYWzcNZoeifGeB2SMSHJkoIJeu9n7ef/vbKWHvHRLJo1mi7trNsKYwLFkoIJan/KzOXRNzcxuFs70meMokPbCK9DMiakBfSxTxG5TkS2i8gOEXm0gTK3i0iWiGwRkVcCGY9pXuZ8tJPvvb6Rcb078srsMZYQjGkCAbtSEJEw4HfANUAesFpElqlqlk+ZvsBjwHhVPSIiSYGKxzQfqsov3tvO7z/8ghuGdOFXd1xMm9ZhXodlTIsQyOqj0cAOVd0JICJLgUlAlk+Ze4HfuX0qoaoHAhiPaQYqq5TH39rEkoxc7hzTg59MGkxYK+u2wpimEsjqo25Ars98nrvMVz+gn4isEJFPReS6+jYkIveJSKaIZBYUFAQoXOO10opKHnhlLUsycnngij787CZLCMY0Na8bmlsDfYHLcbrl/o+IDFHVo76FVLWmZ9a0tDRt6iBN4BWXVnD/okxW7DjE4zcMZPaXLvI6JGNapEAmhT2Ab4c0ye4yX3nAKlUtB3aJyGc4SWJ1AOMyQebw8TJmzs9g895C/ve2i7llZLLXIRnTYgWy+mg10FdEeolIBDAZWFanzFs4VwmISAJOddLOAMZkgszeoye57Q8r2baviP+bOtISgjEeC9iVgqpWiMgDwHtAGDBPVbeIyNNApqouc9d9WUSygErge6p6KFAxmeDEhrcmAAAUPElEQVSy40Ax0+auoqikgoX3jGbMRR29DsmYFk9Um1cVfVpammZmZnodhjlPG/OOMmP+aloJLLhnNIO6Wj9GxgSSiKxR1bTGynnd0GxaoJU7DnLvwkw6tI1g8awxpCS09TokY4zLkoJpUn/bnM+DS9bTK6EtC2eNplNcpNchGWN8WFIwTebV1bt57M1NDOvennkzRtE+2rqtMCbYWFIwTeIP//6CZ5Zv47J+ibw4dQTREfZfz5hgZL9ME1CqyjPLt/F//9nJxIu78svbLiaidUD7YTTGnAdLCiZgKiqr+OGfN/FaZh7TLunJk18dRCvrtsKYoGZJwQRESXklDy5Zx9+z9vPQVX15+Oq+iFhCMCbYWVIwF1xRSTn3Lszk052HefKrqcwY38vrkIwxfrKkYC6og8WlzJifwbb8Ip67Yxg3Da/bMa4xJphZUjAXTN6RE0ybm8HeYyf547Q0rhhgYyYZ09xYUjAXxOf7i7h7bgYnyipYPGsMaSnxXodkjDkHlhTMeVu3+wgz01cTHtaKV++/hIFd4rwOyRhzjiwpmPPy0ecF3L9oDQkxbVg8aww9OkZ7HZIJVmUnoHg/FB9w/p44BBExENUBojs4f6PioU0ctLJnWbxiScGcs79uzOfhV9fRJymWBfeMIinW+jFqcaqqnIN78b7aA37RvtoDf83rAJQW+rdNCYOo9k6CiOoA0fG1CcM3edSsc6cj2oLd9nzeLCmYc/Lyqhwef2szaT07MGf6KNpFhXsdkrmQyo47B/Min4O674G/et3xAtDK098fEQsxSRDTCToPcf7GJEFM59rp6I5QfgJOHIaTR+Ck+/fE4VOnC/fC/i3OfFlxwzGHRdSTMDqcnljqJpNwO5nxZUnBnBVV5fcffsEv3tvOlQOS+N2dI4iKCPM6LOOPqko4frD+g3zds/v6Dr4S5h7Yqw/2Q90DfCeI7eRz4O/knLUHQkWpm0COnJpMTkssR+DwLji5xllXWdrwNsOj/bsSOSWxtIew0DwRsqRg/FZVpfzs3a3M/XgXXxvejWdvHUp4mNX9eq60+NSqmobO7o8XgFad/v42cbUH9y4X13OQd8/uo+OhlccnAK3bQGxn5+UvVSg/2fCVSN0kc2Br7Xx9V0HV2sTVfyVS71WJWy6yfdC3l1hSMH4pr6ziB69v5M11e5g5PoUf3ZBq/RgFUmUFnDhY5wx+36lVN9UH+/Ljp7+/VWto657Vx3WDrsNrD/y+Z/dtkyAixG8OEHG+Y0Q0tDuLMcBVobSozpXIkYYTy5Fsd/1RoKERLaWe9pJ6kkfddW1im6y9xJKCaVRJeSUPvLKWf2w9wHeu6ccDV/axfozORfVBprGDfPE+p5qnvgNLZLvag3q3kbVn87Gda6tuYjo7B5IgPyMNeiIQGee8OqT4/76qSig55kcV12Hn37xgm1PdVVbU8DZbtXb+Ta95Gobded5f7UwsKZgzKiwpZ3Z6JqtzDvOTmwZz99ieXocUnCrKoGCrc2bf0Nl98QGnYbWuVuG1B/d2yZA88tT6+ZjqA34ShEc1/XczZ6dVmHOWHx0PHXv7/77K8jNfiZw8DO17BC5ulyUF06ADRSVMn7eaHQeK+O2U4dw4tKvXIQWP8hLYswZyVkD2x5CbARUnTy0T2b72DD55VJ3qm+qz+07Nop7ZNIGw8Nrk7yFLCuY0qsonOw/x2JubOFBYytzpo7i0X6LXYXmr7ATkZUDOSsheAXmra+9o6TQYRkyDHmOgfc/ag37rNt7GbMw5sKRgapwsq+St9XtIX5HN9v1FJMS04eV7xzCiRwevQ2t6pcWQ+6mTAHJWwJ61UFUO0sq5737UbEgZDz0ucaoJjAkRlhQMe46eZOEn2SzNyOXYyXJSu8Txi1uH8tWLuxIZ3kKeQSg5Brs/daqCclbA3vXO7YgS5ty5c8k3oecE52ogsp3X0RoTMJYUWihVJWPXYdJXZvPeln2ICNcO6sSMcb0YldIh9O8uOnHYqQqqbhPYv9m5h79VuHNXz4SHoed46D4G2sR4Ha0xTcaSQgtTUl7JsvV7mb8ym635hbSPDuf+y3ozdWxPurUP4TtbigucBJCzwqkSOrDFWR7WBrqPhku/Dz3HOQ3CoX7fvjFnYEmhhdh79CSLP81hScZujpwoZ0DnWP7nliFMGtYtNKuICvNPTQIHtzvLw6OdJDDocadNoNtIaxA2xkdAk4KIXAc8D4QBc1T1mTrrZwC/APa4i15Q1TmBjKklUVUyc46QviKbv23Zh6pyTapTRTT2ovjQqiI6mltbFZSzAg7vdJZHxEKPsXDxZEiZAF2GQesIb2M1JogFLCmISBjwO+AaIA9YLSLLVDWrTtFXVfWBQMXREpWUV/LOxnzSV+5i855C4iJbM3tCL6aO7Un3+BCoGlF1uhSovgrI+RiO7nbWRbaDHuMg7R6nTaDzUAizC2Jj/BXIX8toYIeq7gQQkaXAJKBuUjAXyP7CEhZ/msMrq3Zz6HgZ/TrF8POvDeGm4V2JjmjGB0ZVOLSj9iogZyUUuheXUfFOW8DYbzpJoNMg7zttM6YZC+SRohuQ6zOfB4ypp9wtInIp8BnwbVXNrVtARO4D7gPo0SPwj3k3J6rK2t1HSV+ZzfJN+VSqcvXATswcl8IlvTs2zyoiVac/GN8kULzfWdc2yWkL6DneqQ5K6G9PAxtzAXl9+vgXYImqlorI/cAC4Mq6hVT1JeAlgLS0tIa6H2xRSisqeXdTPukrstmQd4zYyNbMGJfCtEtSmt+QmFVVzt1A1VVBOSud0bwAYrtCr0trk0DHPja6ljEBFMiksAfo7jOfTG2DMgCqeshndg7wbADjCQkHikp4+dPdvLxqNweLS+md2Jaf3DSYm4d3o20br3O8nyorYN/G2jaB3Sudh8fA6fCr77Xu1cA46NDLkoAxTSiQR5HVQF8R6YWTDCYDp/T5KiJdVDXfnZ0IbA1gPM3a+tyjpK/YxV835VNRpVzZP4kZ41OY0Cch+KuIKsudJ4RzPnaTwKe13QTHXwQDJzpXAT3HQ/vuZ96WMSagApYUVLVCRB4A3sO5JXWeqm4RkaeBTFVdBjwoIhOBCuAwMCNQ8TRHZRVVLN+cz/wV2azPPUpMm9ZMHduT6ZekkJIQoOEOL4SKUqcH0ep+g3IzageCSegPQ26tTQJxXbyN1RhzClFtXlX0aWlpmpmZ6XUYAVVQVMqSjN0s/jSHA0WlXJTQlunjUrhlZDIxwVhFVH7S6TW0OgnkrYaKEmdd0qDahuGe4yGmhfe2aoxHRGSNqqY1Vi4IjzAt16a8Y8xfuYt3NuRTVlnF5f0TeXZcCpf2TQyuoS/LjkPuKp8eRNdAZRkgTg+i1c8I9BxnPYga08xYUvBYeWUVf9u8j/SV2azJOULbiDCmjO7OtHEp9E4Mko7YSgqddoDqO4P2roOqCrcH0WEw5utOdVD3Mc74s8aYZsuSgkcOFZeydHUuiz7JYV9hCT07RvPEjancmpZMXGS4d4FVlMLBz+DAVsjf4DwrsG+jTw+iI2Dcg06VUPcxzoDixpiQYUmhiW3Ze4z0Fdm8vWEvZRVVfKlvAj+/eTCX90tq2iqiqkqnq4gDWbA/y/l7YKvz5LBWOmXC2ji9hn7pu04SSB5tPYgaE+IsKTSBisoq/p61n/QV2WRkHyYqPIzb05KZfkkKfTsF+ExbFYryTz3wH9gCBdtrG4MR6JACSamQOhGSBjrTHfs448YaY1oMSwoBdOR4mVtFlM3eYyV0j4/i8RsGcltad9pFBeBge+Kwe9DP8vmbVftgGEBMZ+egP2p27cE/sT9EBPEtrsaYJmNJIQC25heyYGU2f163h9KKKsb36chTkwZz5YAkwi5EFVHZCadvIN8D/4GtzhVBtTbtoFMqDL7FOfAnpTpJwO4GMsacgSWFC6SySnk/az/pK3fx6c7DRIa34uYRycwYl0L/zudYRVRZDoe+OP3M//AuwH2+pHWkc6Z/0eXumf8g529cV+sewhhz1iwpnKejJ8p4dXUuCz/JYc/Rk3RrH8Vj1w/gjlHdaR/t52AuVVVwLPf0M/+Dn7n3/wPSyqnj7zwEht5Re/Yf38u6ijbGXDCWFM7RZ/uLSF+ZzZtr8ygpr2LsRfH86MZUrh6YROuwM3TlXFzgc+CvvgLYCmXFtWXadXfO9vtcXVvtk9APwiMD/8WMMS2aJYWzUFml/GvbAdJX7mLFjkO0ad2Km4Z1Y/q4FFK7xp1auLQIDmxz7vSpvgLYnwUnDtaWiYp3BoUZdldto2/SAGf0MGOM8YAlBT8cO1nOnzJzWfBJNrmHT9KlXSTfv64/k0f1IL6NwsHPYaPPmf/+LDi2u3YD4W2dg33/62vP/DsNgraJVu9vjAkqlhTOYMeBIhaszOGNtXmUlJVzQ3IZzw09zrA2+YQVLIL5Wac+7NUq3Knm6T4aRk53EkCnVGjXw0YHM8Y0C5YU6qiqrGLlhk2sXPkxZflbGB6Wy33R++kWnkOrgyVwEE552GvgV50Df1IqxPeG1n42LhtjTBBq2Unh5JGa+v6yvZs5vGsD0Uc/YwLFTAAIh8q2nQjrlApJV7sH/4GQOMAe9jLGhKSWkxQO74Ldn8D+LbV3/BTtrVldotHkajKH215K134jGHjxWFp3HkSYPexljGlBWk5S2LoM3n8Cwtqgif3Z33EMH4Yl8LcDHfhCejBqyGCmj+/Ftd2t62djTMvVcpLC0Mkc73Utb+wKJ/2TXHZmHycxtg1Tr+zJs2O6kxRrzwAYY0yLSQqvbivlJ+/kUFxawbDu7Xl+8jCuH9yFiNZ2V5AxxlRrMUmhW/torhqYxIxxKQzv0cHrcIwxJii1mKQwoW8CE/omeB2GMcYENas7McYYU8OSgjHGmBqWFIwxxtSwpGCMMaaGJQVjjDE1LCkYY4ypYUnBGGNMDUsKxhhjaoiqeh3DWRGRAiDnHN+egDsiQpCxuM6OxXX2gjU2i+vsnE9cPVU1sbFCzS4pnA8RyVTVNK/jqMviOjsW19kL1tgsrrPTFHFZ9ZExxpgalhSMMcbUaGlJ4SWvA2iAxXV2LK6zF6yxWVxnJ+Bxtag2BWOMMWfW0q4UjDHGnIElBWOMMTVCMimIyHUisl1EdojIo/WsbyMir7rrV4lISpDENUNECkRkvfua3URxzRORAyKyuYH1IiK/cePeKCIjgiSuy0XkmM/+eqIJYuouIh+ISJaIbBGRh+op0+T7y8+4vNhfkSKSISIb3LieqqdMk/8e/YzLk9+j+9lhIrJORN6pZ11g95eqhtQLCAO+AC4CIoANQGqdMt8E/uBOTwZeDZK4ZgAveLDPLgVGAJsbWP8VYDkgwFhgVZDEdTnwThPvqy7ACHc6Fvisnn/HJt9ffsblxf4SIMadDgdWAWPrlPHi9+hPXJ78Ht3PfgR4pb5/r0Dvr1C8UhgN7FDVnapaBiwFJtUpMwlY4E6/DlwlIhIEcXlCVf8DHD5DkUnAQnV8CrQXkS5BEFeTU9V8VV3rThcBW4FudYo1+f7yM64m5+6DYnc23H3VvbulyX+PfsblCRFJBm4A5jRQJKD7KxSTQjcg12c+j9N/HDVlVLUCOAZ0DIK4AG5xqxxeF5HuAY7JX/7G7oVL3CqA5SIyqCk/2L1sH45zlunL0/11hrjAg/3lVoWsBw4A76tqg/urCX+P/sQF3vwenwO+D1Q1sD6g+ysUk0Jz9hcgRVWHAu9TezZg6rcWpz+Xi4HfAm811QeLSAzwBvCwqhY21ec2ppG4PNlfqlqpqsOAZGC0iAxuis9tjB9xNfnvUURuBA6o6ppAf1ZDQjEp7AF8M3qyu6zeMiLSGmgHHPI6LlU9pKql7uwcYGSAY/KXP/u0yalqYXUVgKq+C4SLSEKgP1dEwnEOvC+r6pv1FPFkfzUWl1f7y+fzjwIfANfVWeXF77HRuDz6PY4HJopINk4V85UisrhOmYDur1BMCquBviLSS0QicBpiltUpswyY7k7fCvxL3VYbL+OqU+88EadeOBgsA6a5d9WMBY6par7XQYlI5+q6VBEZjfP/OaAHE/fz5gJbVfVXDRRr8v3lT1we7a9EEWnvTkcB1wDb6hRr8t+jP3F58XtU1cdUNVlVU3COEf9S1al1igV0f7W+UBsKFqpaISIPAO/h3PEzT1W3iMjTQKaqLsP58SwSkR04DZmTgySuB0VkIlDhxjUj0HEBiMgSnDtTEkQkD/gxTsMbqvoH4F2cO2p2ACeAmUES163AN0SkAjgJTG6C5D4euBvY5NZHA/wQ6OETlxf7y5+4vNhfXYAFIhKGk4ReU9V3vP49+hmXJ7/H+jTl/rJuLowxxtQIxeojY4wx58iSgjHGmBqWFIwxxtSwpGCMMaaGJQVjjDE1LCkYU4eIVPr0jLle6unR9jy2nSIN9PpqTDAIuecUjLkATrrdHxjT4tiVgjF+EpFsEXlWRDa5ffH3cZeniMi/3I7T/ikiPdzlnUTkz24HdBtEZJy7qTAR+aM4/fj/3X2i1pigYEnBmNNF1ak+usNn3TFVHQK8gNObJTidyy1wO057GfiNu/w3wL/dDuhGAFvc5X2B36nqIOAocEuAv48xfrMnmo2pQ0SKVTWmnuXZwJWqutPtfG6fqnYUkYNAF1Utd5fnq2qCiBQAyT6dqlV3a/2+qvZ1538AhKvqTwP/zYxpnF0pGHN2tIHps1HqM12Jte2ZIGJJwZizc4fP30/c6ZXUdkp2F/CRO/1P4BtQM6BLu6YK0phzZWcoxpwuyqenUYC/qWr1bakdRGQjztn+FHfZt4D5IvI9oIDaXlEfAl4SkVk4VwTfADzvctyYM7E2BWP85LYppKnqQa9jMSZQrPrIGGNMDbtSMMYYU8OuFIwxxtSwpGCMMaaGJQVjjDE1LCkYY4ypYUnBGGNMjf8PLB8Jes0caLsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot history\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model Accuracies')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes on experimental architectures:\n",
    "# With stop word removal, demojizing, string.punctuation word remova, vocab size 30000, padding at 50, get 0.56 val accuracy \n",
    "# decreasing vocab size to 5000 causes bad results and strange effects\n",
    "# adding dropout layers made it worse by 2% therefore removed dropout layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weights from the model with the best val accuracy\n",
    "model.load_weights(weightsFilePath)\n",
    "y_pred = model.predict(x_val)\n",
    "y_pred = np.array([[1 if i == max(sc) else 0 for i in sc] for sc in y_pred])\n",
    "y_pred_text = onehot_encoder.inverse_transform(y_pred)\n",
    "y_val_text = onehot_encoder.inverse_transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_val_text, y_pred_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averageFScore(cm):\n",
    "    (noClasses,_) = cm.shape\n",
    "    fsum = 0\n",
    "    recalls = []\n",
    "    precisions = []\n",
    "    for i in range(noClasses):\n",
    "        correct = cm[i][i]\n",
    "        # if row or col total is zero set to 1 to avoid nans\n",
    "        rowTotal = max(sum(cm[i]),1)\n",
    "        colTotal = max(sum(cm[:,i]),1)\n",
    "        recall = correct / rowTotal\n",
    "        recalls.append(recall)\n",
    "        precision = correct / colTotal\n",
    "        precisions.append(precision)\n",
    "        \n",
    "        # Get denominator, if 0 set to 1 to avoid nans\n",
    "        denominator = precision + recall if precision + recall > 0 else 1\n",
    "        f1 = 2*precision*recall / denominator\n",
    "        fsum += f1\n",
    "    return fsum/noClasses, recalls, precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[157 104  24]\n",
      " [ 69 225  74]\n",
      " [ 19  90  77]]\n",
      "Average fscore: 0.5302790805652039\n",
      "valAccuracy 0.5470798569725864\n",
      "Recalls for each class: [0.5508771929824562, 0.6114130434782609, 0.41397849462365593]\n",
      "Precisions for each class [0.6408163265306123, 0.5369928400954654, 0.44]\n"
     ]
    }
   ],
   "source": [
    "# Rows are the actual, columns are the predicted.  negative, neutral, positve\n",
    "print(cm)\n",
    "valAccuracy = (cm[0][0] + cm[1][1] + cm[2][2])/sum(sum(cm))\n",
    "avgfscore, recalls, precisions = averageFScore(cm)\n",
    "print(f\"Average fscore: {avgfscore}\")\n",
    "print(f\"valAccuracy {valAccuracy}\")\n",
    "print(f\"Recalls for each class: {recalls}\")\n",
    "print(f\"Precisions for each class {precisions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance on Test Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "testdf = pd.read_csv('./SemEval2017-task4-test/SemEval2017-task4-test.subtask-A.arabic.txt', sep='\\t', header=None, keep_default_na=False)\n",
    "testdf.columns = ['id','label','raw']\n",
    "\n",
    "testdf['text'] = testdf.apply(lambda row: preprocess(row['raw'], stop_words),axis=1)\n",
    "testdf['numSeq'] = testdf.apply(lambda row: convertTextToNumSeq(row['text'], word2idx, MAXIMUM_LENGTH),axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral     2364\n",
      "negative    2222\n",
      "positive    1514\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x_test = testdf['numSeq']\n",
    "y_test = testdf['label']\n",
    "\n",
    "# Prelim analysis to indicate class imbalance\n",
    "print(y_test.value_counts())\n",
    "\n",
    "# Onehot encode the y data\n",
    "y_test = onehot_encoder.transform(np.array(y_test).reshape(len(y_test),1))\n",
    "x_test = np.array([x for y in x_test for x in y]).reshape(len(x_test),MAXIMUM_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions and prepare data for confusion matrix\n",
    "y_testpred = model.predict(x_test)\n",
    "y_testpred = np.array([[1 if i == max(sc) else 0 for i in sc] for sc in y_testpred])\n",
    "y_testpred_text = onehot_encoder.inverse_transform(y_testpred)\n",
    "y_test_text = onehot_encoder.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 775 1233  214]\n",
      " [ 371 1694  299]\n",
      " [ 198  929  387]]\n",
      "Average fscore: 0.43332829277231094\n",
      "testAccuracy 0.4681967213114754\n",
      "Recalls for each class: [0.3487848784878488, 0.7165820642978004, 0.25561426684280053]\n",
      "Precisions for each class [0.5766369047619048, 0.43931535269709543, 0.43]\n"
     ]
    }
   ],
   "source": [
    "# Create confusion matrix and get some key information from it. \n",
    "cm = confusion_matrix(y_test_text, y_testpred_text, labels=['negative','neutral','positive'])\n",
    "\n",
    "print(cm)\n",
    "testAccuracy = (cm[0][0] + cm[1][1] + cm[2][2])/sum(sum(cm))\n",
    "avgfscore, recalls, precisions = averageFScore(cm)\n",
    "print(f\"Average fscore: {avgfscore}\")\n",
    "print(f\"testAccuracy {testAccuracy}\")\n",
    "print(f\"Recalls for each class: {recalls}\")\n",
    "print(f\"Precisions for each class {precisions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix shows prediction in columns of negative, neutral and positive. Groundtruth are in rows of negative, neutral and positive. \n",
    "Test accuracy is 46.8%. We can see from the confusion matrix that the classifier particularly struggles to classify when the text is neutral, its recall of positive samples is 25.5%. Therefore to help improve this model we could try concentrating on features that help to classify positive text. The fact that the model is worse than guessing when the data is positive is concerning and suggests there is a lot of room for improvement. We would expect that the neutral class is the hardest to classify though as it's most similar to the two other classes. Both the training and test data have a class imbalance. Future work could try addressing this class imbalance. I think large difference between the neutral and the positive recalls shows the model struggles to distiguish between them and has placed its decision boundary to get more of the neutral cases right. The positive class si the smallest in both the test and the training data, which may explain why the model has done this. If we wanted to identify neutral tweets then this model would be very useful but most applications would want to classify the negative or the positive tweets, so the future work may want to incentivise the model to improve recall on negative and positive classes, either by balancing the data or creating a custom loss function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eenlp",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
